---
title: "Ejemplos Modulo 2"
author: "Goijman, Serafini, Contreras"
date: '2023-03-14'
output: html_document
---

Cargamos la librería `jagsUI` para correr JAGS 
```{r setup, error=TRUE}
library(jagsUI)    #paquete JAGS
```
Ejemplo tamaño medio de zorzales (n=10)

Agrupar los datos en una lista para que pueda ser leida por JAGS
```{r, error=TRUE}
data <- list(size = c(7.9,8.1,11,10.6,9.2,8,9.8,10.1,10.9,9))
```

Modelo para pasarle a `jags`
es muy importante el nombre del archivo (también podríamos escribirlo en un archivo de texto)
```{r, error=TRUE, include=FALSE}
sink("zorzales.jags")
cat("

model
{
# previas no informativas
mean ~ dnorm (0, 1.0E-6)  # tamaño medio de los zorzales
varianza ~ dlnorm (0 ,1.0E-6)  # varianza tamaño zorzales

prec <- 1/varianza             # pasar de varianza a precision 

for (i in 1:10)            # para cada uno de los Zorzales
{
size[i] ~ dnorm (mean, prec)   # tamaño zorzal trazado de una distribución normal
}
}

",fill = TRUE)
sink()
```

Valores Iniciales para correr las cadenas de Markov (MCMC)
```{r, error=TRUE}
inits <- function() list(varianza=100, mean = 10)

```

Seteo para correr MCMC donde incicamos cuántos valores vamos a ir descartado en una secuencia (“thin”), qué largo tiene el “burn in” y cuántas cadenas queremos correr.
```{r, error=TRUE}
ni <- 10000  # número de iteraciones
nt <- 2      # tasa de thining
nb <- 1000   # iteraciones para el burn in
nc <- 3      # número de cadenas que corremos
```

Le decimos a `jags`que parámetros nos interesa monitorear
```{r, error=TRUE}
parameters <- c("mean", "varianza")
```
Para llamar a `JAGS` desde `R` usamos el paquete `jagsUI` que cargamos anteriormente y la función `jags` de ese paquete
```{r, error=TRUE, include=FALSE}
out <- jags(data, inits, parameters, "zorzales.jags", n.chains = nc, n.thin = nt, n.iter = ni, n.burnin = nb)
```

Corremos modelo...
```
Processing function input....... 

Done. 
 
Compiling model graph
   Resolving undeclared variables
   Allocating nodes
Graph information:
   Observed stochastic nodes: 10
   Unobserved stochastic nodes: 2
   Total graph size: 19

Initializing model

Adaptive phase..... 
Adaptive phase complete 
 

 Burn-in phase, 1000 iterations x 3 chains 
 
  |**************************************************| 100%

Sampling from joint posterior, 9000 iterations x 3 chains 
 
  |**************************************************| 100%

Calculating statistics....... 

Done. 
```

Para ver los resultados le pedimos a `R` que muestre la salida de la función jags llamando a "out", que es el nombre que le dimos. 

```{r, error=TRUE}
out
```
JAGS output
```
JAGS output for model 'zorzales.jags', generated by jagsUI.
Estimates based on 3 chains of 10000 iterations,
adaptation = 100 iterations (sufficient),
burn-in = 1000 iterations and thin rate = 2,
yielding 13500 total samples from the joint posterior. 
MCMC ran for 0.003 minutes at time 2023-03-14 14:21:01.

           mean    sd   2.5%    50%  97.5% overlap0 f  Rhat n.eff
mean      9.457 0.435  8.593  9.455 10.332    FALSE 1 1.000 13500
varianza  1.888 1.256  0.673  1.569  4.893    FALSE 1 1.002 13500
deviance 33.221 2.291 31.029 32.536 39.295    FALSE 1 1.000 13500

Successful convergence based on Rhat values (all < 1.1). 
Rhat is the potential scale reduction factor (at convergence, Rhat=1). 
For each parameter, n.eff is a crude measure of effective sample size. 

overlap0 checks if 0 falls in the parameter's 95% credible interval.
f is the proportion of the posterior with the same sign as the mean;
i.e., our confidence that the parameter is positive or negative.

DIC info: (pD = var(deviance)/2) 
pD = 2.6 and DIC = 35.845 
DIC is an estimate of expected predictive error (lower is better).
```
Se indica el nombre del modelo que se usó, cuántas cadenas se simularon y cuántas iteraciones hubo. También tenemos el de "muestras totales" teniendo en cuenta el burn-in y el thinning. 
Luego podemos ver tabla con la lista de parámetros que le pedimos que registre (en este caso la media y la varianza) y la devianza. En la tabla aparece la media, desvío y cuantiles estimados a partir de las cadenas de Markov. 
También aparece una columna (overlap0) que nos dice si la posterior incluye al cero o no, y otra (f) que nos dice qué fracción de la posterior es del mismo signo que la media. 
Rhat estima si las cadenas convergieron a una distribución estable y n.eff estima el número efectivo de muestras de la posterior que surgen de las cadenas. 
Antes de sacar cualquier conclusión, tenemos que chequear que haya convergencia de las cadenas (Rhat ≤1.1). 

También podemos ver todo lo que tiene guardada la salida con 
```{r, error=TRUE}
str(out)
```

Podemos (y debemos) inspeccionar visualmente la salida del MCMC
```{r, error=TRUE}
plot(out)
```

Cuando tengamos muchos parámetros, podemos "llamar" a aquellos que nos interesen
```{r, error=TRUE}
traceplot(out, parameters=c("mean", "varianza")) 
```
